{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd899bc",
   "metadata": {},
   "source": [
    "This notebook is about the general workflow procedure for an image classification task. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988876b2",
   "metadata": {},
   "source": [
    "# Steps involved in image classification task\n",
    "1. Data acquisition\n",
    "2. Data processing\n",
    "3. Model building\n",
    "4. Model compilation\n",
    "5. Model training\n",
    "6. Model evaluation\n",
    "7. Model predictions\n",
    "8. Deployment of model as app, web, IoT etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142661d",
   "metadata": {},
   "source": [
    "We will be using tensorflow and keras for performing image classification. These are popular deep learning frameworks and are very user friendly, ideal for beginners. These libraries contain function to prepare the data, build models, compile, train, evaluate them and use them for prediciton and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42038e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # numpy- NUMerical PYthon, used for array based operations\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787012d3",
   "metadata": {},
   "source": [
    "# Data acquisition "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47ab1ff",
   "metadata": {},
   "source": [
    "We are dealing with images, hence our data would be an image dataset. If you are working with google colab then you can go with datasets in google drive. There is an option to integrate the drive with colab. \n",
    "\n",
    "If you are using jupyter notebook, then you need to keep the dataset in the local machine (computer) and then mention the location in notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aaeea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if using colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "train_path='/content/drive/MyDrive/Dataset/train'\n",
    "test_path='/content/drive/MyDrive/Dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac3a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if using jupyter\n",
    "train_path='C:\\Users\\sairam\\Desktop\\data science\\datasets\\train'\n",
    "test_path= \"C:\\Users\\sairam\\Desktop\\data science\\datasets\\test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866215f5",
   "metadata": {},
   "source": [
    "This is the general format for an image dataset. The train folder images are used to train the model and the test folder images are used to validate/test the trained model. Generally, 80% of data are kept in train and 20% in test.\n",
    "\n",
    "DIRECTORY\n",
    "       TRAIN\n",
    "           class 1\n",
    "               Image 1\n",
    "               Image 2\n",
    "               Image 3\n",
    "               .\n",
    "               .\n",
    "               Image n\n",
    "           class 2\n",
    "               Image 1\n",
    "               Image 2\n",
    "               Image 3\n",
    "               .\n",
    "               .\n",
    "               Image n\n",
    "        TEST\n",
    "            class 1\n",
    "               Image 1\n",
    "               Image 2\n",
    "               Image 3\n",
    "               .\n",
    "               .\n",
    "               Image n\n",
    "           class 2\n",
    "               Image 1\n",
    "               Image 2\n",
    "               Image 3\n",
    "               .\n",
    "               .\n",
    "               Image n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff28f27a",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef3c447",
   "metadata": {},
   "source": [
    "The main work in data processing in relation to image classification is to prepare the data. We also perform an operation called as augmentation, an attempt to improve the size of the dataset. This is done by creating copies of images by applying different operations. \n",
    "\n",
    "The function in keras to perform augmentations is **ImageDataGenerator**. The imagedatagenerator is used to implement data augmentation. We can process the image as we want and create batches of image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c565dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(rescale = 1./255, zoom_range = 0.2, width_shift_range= 0.2, height_shift_range= 0,2,vertical_flip=True)\n",
    " \n",
    "test_dataset = image.ImageDataGenerator(rescale=1./255) #no transformations are applied to the testing dataset to maintain its originality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928bbf12",
   "metadata": {},
   "source": [
    "Rescaling refers to the conversion of scale (range) of data. The images in digital world have pixels whose intensities range from 0 to 255 where black being 0 and white being 255. Dividing all the pixels by the max value (255) will it to convert to decimals values ranging from 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8367b61a",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dac0f16",
   "metadata": {},
   "source": [
    "The next step in data processing involves the preparation of data for model. There are two functions present in keras for this and these methods are based on the type of dataset. \n",
    "\n",
    "The first method is called as flow_from_directory. This method is applicable when you have the data in folders with the class name. The second method is called as flow_from_dataframe. This method is applicable when you have the images in folders and the corresponding class in present in excel sheet (dataframe).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf9ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/content/drive/MyDrive/Dataset/train',\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary') ## or 'categorical'\n",
    "validation_generator = test_dataset.flow_from_directory(\n",
    "    '/content/drive/MyDrive/Dataset/val',\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    shuffle=True,\n",
    "    class_mode = 'binary') ## or 'categorical'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f326626",
   "metadata": {},
   "source": [
    "Here we mention the location of images, the target size we want (because model accepts same size images only), batch size (no of images processed at a time: more batch (less time, less acc) less batch (more time, more acc), and type of class (either binary or categorical). Note that the transforms we mentioned before are applied to that input images in this step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25067094",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaaa7c3",
   "metadata": {},
   "source": [
    "The next step is to create the deep learning algorithm. The algorithms used for image classification in the field of deep learning is CNN (Convolutional Neural Network). A base CNN comprises of four layers, convolution, pooling, flatten and dense. \n",
    "\n",
    "However, basic CNN's take a lot of time to train and produce good results. Hence to bypass this we go for a concept called as transfer learning. As the name suggests, we take a CNN that is trained on a task, modify it and use it for our task. It is our wish to train them or not (freezing). This method greatly conserves time and these models are known to produce good results for images in general. \n",
    "\n",
    "The CNN models (pre-trained) can be obtained from this link...\n",
    "https://keras.io/api/applications/\n",
    "\n",
    "The pre-trained versions of different models are present here, we can download the weights of these CNNs and use for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae23b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_for_model = tf.keras.applications.MobileNetV2(weights='imagenet', input_shape=(224,224,3), include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb29b3",
   "metadata": {},
   "source": [
    "All of these models are trained on ImageNet, which is a 1000 class dataset. So we need to remove the last layer (since it has 1000 neurons for 1000 classes) and add our own layer to it. input_shape=(224,224,3) => this is the input dimensions of the model. this is the parameter mentioned in the processing part. the 3 refers to the three channels R,G,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4105fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_for_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7358fba3",
   "metadata": {},
   "source": [
    "Now we are freezing the layers present in the pre-trained model. These layers wont participate in training and this would greatly contribute in conservation of time. If kept true then those layers also train and this is called as fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aefa865",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for binary\n",
    "model = Sequential()\n",
    "model.add(base_for_model) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b8f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for multiclass\n",
    "model = Sequential()\n",
    "model.add(base_for_model) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_classes, activation='softmax')) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1c9158",
   "metadata": {},
   "source": [
    "The Sequential method from keras creates an empty container onto which we stack up our layers. We append Flatten to the pre-trained model so that we convert the 2-D to 1-D for dense layers. Then we append the output layer which differs in the case of binary and multiclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffd3635",
   "metadata": {},
   "source": [
    "# Model compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a071b5c",
   "metadata": {},
   "source": [
    "Before training the model, it is important to compile the model with some parameters. There are three parameters used to compile a model.\n",
    "\n",
    "1. Loss function- mention what function you are going to use to compare the model prediction with that of truth\n",
    "https://keras.io/api/losses/\n",
    "\n",
    "2. optimizer- mention what optimiser you are going to use to update the weights and biases of the CNN using loss function\n",
    "https://keras.io/api/optimizers/\n",
    "\n",
    "3. metrics- mention what metrics you are going to use to monitor the performance of model\n",
    "https://keras.io/api/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9910d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary\n",
    "model.compile(optimizer='adam',loss= 'binary_crossentropy', metrics='binary_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa2d26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiclass\n",
    "model.compile(optimizer='adam',loss= 'categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5810fde8",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab70add",
   "metadata": {},
   "source": [
    "Once we have compiled, the model is good to go for training. We use the training images to train the model. The function used for this is model.fit()\n",
    "\n",
    "epochs refers to the stages of training. It is of the users choice. For each epoch, there are some steps, this is mentioned by steps_per_epoch. There is a formula to calculate the steps. it is Steps_per_epoch= Training images/batch size. You can fix the steps within the value, going beyond this will cause error.\n",
    "\n",
    "Fitting images into a model and training takes a lot of time. The reason is that the optimiser needs to calculate the weight and bias for millions of neurons in every stage. We can use GPU to boost the computation power and lessen the time taken. Google Colab and Kaggle provide free gpu through cloud. NVIDIA provides graphic cards with gpu to train CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d057674",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=19,\n",
    "    epochs = 15, #own choice\n",
    "    validation_data = validation_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318b5b5b",
   "metadata": {},
   "source": [
    "**Note- If the accuracy increases and loss decreases in every epoch, then it means the model is training. Also if the loss value is very high or negative, then it means you are using the wrong function (binary loss for categorical task and vice versa)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1a53c2",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2b5796",
   "metadata": {},
   "source": [
    "Here we evaluate the performance of the trained model. The values shown during training refer to in each epoch. The values shown here refer to those of the completely trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44763e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train_generator)\n",
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00af8433",
   "metadata": {},
   "source": [
    "The results produced for the validation data is more important than that of training. Because the validation images are not exposed to the model and the prediction on those are equivalent to real time predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70510193",
   "metadata": {},
   "source": [
    "# Model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557b3be1",
   "metadata": {},
   "source": [
    "Now we can use the trained model to predict on new images. We need to process the input image before feeding it to the model. It involves resizing to target size, converting to array and then adding a dimension at the end (for color channel). Then we give it to the model for prediction. It will return an array from which we infer the output, it differs in binary and categorical. \n",
    "\n",
    "\n",
    "Binary\n",
    "it returns an array with one element. If that element is less than 0.5, we assign it to class 0 or we assign it to class 1. We do this because we have used sigmoid activation function.\n",
    "\n",
    "\n",
    "Multiclass\n",
    "it returns an array with elements equal to number of classes. Out of those elements, only one value would be the maximum. It means that the model is predicting the image to be that class. We need to find the class pertaining to the position of the maximum element. This is done by argmax function in numpy. We do this because we use softmax activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce119478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "img = load_img('abc.jpeg',target_size=(224,224))\n",
    "img = img_to_array(img)\n",
    "img = np.expand_dims(img,axis=0)  \n",
    "ypred = model.predict(img)\n",
    "ypred=ypred[0]\n",
    "if ypred>0.5:\n",
    "    ypred=\"class_1\"\n",
    "else:\n",
    "    ypred=\"class_0\"  \n",
    "print(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a26b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiclass\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "img = load_img('abc.jpeg',target_size=(224,224))\n",
    "img = img_to_array(img)\n",
    "img = np.expand_dims(img,axis=0)  \n",
    "ypred = model.predict(img)\n",
    "ypred=np.argmax(ypred,axis=0)\n",
    "if ypred==0:\n",
    "    ypred=\"class_0\"\n",
    "elif ypred==1:\n",
    "    ypred=\"class_1\"\n",
    ".\n",
    ".\n",
    ".\n",
    "elif ypred==n:\n",
    "    ypred='class_n'\n",
    "print(ypred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
